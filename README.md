# ğŸ§  Job Market Data Engineering Pipeline (AWS + Python)

This project builds a serverless data pipeline on AWS to analyze real-time job market data using two public job APIs: **Adzuna** and **Arbeitnow**. It automates ingestion, transformation, and querying using AWS services like **S3, Lambda, Glue, and Athena**.

---

## ğŸš€ Project Overview

- **APIs Used:**  
  - [Adzuna](https://developer.adzuna.com/)  
  - [Arbeitnow](https://documenter.getpostman.com/view/18545278/2s93z9dZgD)

## ğŸš€ Tech Stack

- **Python** (ETL logic)
- **APIs**: Adzuna, Arbeitnow
- **AWS Services**:
  - AWS Lambda (ETL execution)
  - Amazon S3 (storage)
  - AWS Glue (catalog)
  - AWS Athena (SQL querying)
  - Amazon CloudWatch (monitoring)

## ğŸš€ Architecture Overview

1. **Data Ingestion Lambda**
   - Calls **Adzuna** and **Arbeitnow** APIs
   - Combines and stores raw job data to `S3/job_data/` as `.json`

2. **S3 Trigger**
   - Triggers transformation Lambda upon new `.json` in `job_data/`

3. **Transformation Lambda**
   - Applies multiple transformations:
     - Company unification
     - Job title frequency
     - Daily & monthly job trends
     - Top hiring companies
     - Location analysis
     - Contract type distribution
   - Saves CSVs in S3 under structured folders:
     - `processed/cleaned_jobs/`
     - `processed/job_titles/`
     - `processed/daily_postings/`
     - `processed/monthly_postings/`
     - `processed/top_companies/`
     - `processed/location_analysis/`
     - `processed/contract_types/`

4. **AWS Glue Crawler**
   - Crawls S3 `processed/` folder
   - Creates tables in Glue Data Catalog

5. **Athena**
   - Queries data for trend analysis, reports, or dashboards
   - 
![Architecture Diagram.](https://github.com/rushi4git/spotify-end-to-end-data-engineering-project/blob/main/architecture_diagram_spotify.jpg)
---

## ğŸ“‚ Folder Structure in S3
s3://job-market-destination-bucket-rushi/
â”‚
â””â”€â”€ processed/
    â”œâ”€â”€ cleaned_job_data/
    â”œâ”€â”€ job_title_counts/
    â”œâ”€â”€ daily_postings/
    â”œâ”€â”€ monthly_postings/
    â”œâ”€â”€ top_companies/
    â”œâ”€â”€ location_analysis/
    â””â”€â”€ contract_type_distribution/

---

## ğŸ” Transformations Performed

1. âœ… Flatten & unify job data from both APIs  
2. âœ… Job title frequency  
3. âœ… Jobs posted per day  
4. âœ… Jobs posted per month  
5. âœ… Top hiring companies  
6. âœ… Location analysis  
7. âœ… Contract type distribution

Each transformation result is stored as a separate CSV in `processed/`.

---

## ğŸ§ª AWS Setup

### âœ… Lambda Function

- Triggered via S3 event on upload to `job_data/` with `.json` suffix
- Performs all transformations and writes processed CSVs to `processed/` subfolders

### âœ… Glue Crawler

- Points to the `processed/` prefix
- Creates separate tables in a single database (one per transformation output)

### âœ… Athena

- Query the output tables for analytics and visualization

---

## ğŸ› ï¸ How to Run
1.Clone this repo
2.Set up your AWS credentials
3.Deploy the Lambda using AWS Console or SAM/CDK
4.Upload raw .json files into the job_data/ folder in S3
5.Trigger fires â†’ data processed â†’ Glue crawler updates â†’ Athena ready

ğŸ“Œ Future Improvements
1.Add data quality checks
2.Integrate with BI tools like QuickSight

ğŸ§‘â€ğŸ’» Author
Rushikesh Rajulwar
Data Engineer | Python & AWS | [LinkedIn](https://www.linkedin.com/in/rushikesh-rajulwar/).

